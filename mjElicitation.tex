\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}
%\input{preamble/draw}
%\input{preamble/jdoc}
\usepackage{stmaryrd}
\usepackage{xcolor}
\usepackage{siunitx}
\usepackage{relsize}
\pgfplotsset{compat=1.17}
%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Preference Elicitation under Majority Judgment}
\author{}
%\title{The title \thanks{Thanks.}}
%\author{Olivier Cailloux}
%\author{Name2}
%\affil{Université Paris-Dauphine, Université PSL, CNRS, LAMSADE, 75016 PARIS, FRANCE\\
%	\href{mailto:olivier.cailloux@dauphine.fr}{olivier.cailloux@dauphine.fr}
%}
%\author{Name3}
%\affil{Affil2}
%\hypersetup{
%	pdfsubject={},
%	pdfkeywords={},
%}

\begin{document}
\maketitle

\begin{abstract}
\acl{MJ} (\acs{MJ}) is a voting system where voters assign grades to candidates using an ordinal scale. The winner is the candidate with the highest majority-grade \textemdash which is the median of the grades received. This method has attracted increasing attention of french associations and political parties which have started to use \acs{MJ} for internal decisions or local elections. In particular LaPrimaire.org is a french association that uses \acs{MJ} to choose its candidate for the french presidential election. The vote is conducted in two rounds: in the first one the voters judge five candidates randomly picked; the five candidates with the highest medians pass at the second round as finalists and the voters are asked to judge them. Is the random selection of candidates a good elicitation technique? In this paper we explore the consequences of profile incompleteness and we question the elicitation of voters preferences.
\end{abstract}

\section{Introduction}
\label{sec:intro}
\acl{MJ} (\acs{MJ}) is a voting method proposed by \citet{Balinski2007,Balinski2011} to elect one out of $m$ candidates based on the judgments of $n$ voters. The latter express their preferences by assigning to each candidate one of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be rejected. Those adjectives represent a common language whose semantic is assumed to be a shared knowledge among the voters carrying thus an absolute meaning. For each candidate the median of the grades she received is computed, this is called \textit{majority-grade}. The candidate with the highest majority-grade is elected. Ties are broken by considering the majority-grade of first order: one vote associated with the majority-grade of each tied candidates is removed and their medians are recomputed. The candidate with the highest new median is elected. If there is still a tie the process is repeated until a unique winner is found. 

In the last few years \acs{MJ} has being adopted by a progressively larger number of french political parties including: Le Parti Pirate, Génération(s), LaPrimaire.org, France Insoumise and La République en Marche.
%https://www.lopinion.fr/edition/politique/en-marche-teste-elections-jugement-majoritaire-mode-scrutin-tres-201884
"Mieux Voter" \citep{MV} is a french association that promotes the use of \acs{MJ} as voting method whenever a collective choice has to be selected: public administration, associations, companies. On their website it is possible to find all the citizens lists \textendash party lists that are not affiliated to any national political party \textemdash that used \acs{MJ} to rank their candidates during the local elections of 2020. In two cases, Bordeaux et Annecy, the candidate selected using \acs{MJ} was then elected as a mayor. 

In particular, LaPrimaire.org \citep{LaPrimaire} is a french political initiative whose goal is to select an independent candidate for the french presidential election using \acs{MJ} as voting rule. The association Democratech implemented the platform for the first time in 2016 in view of the 2017 presidential elections. The number of voters who participated in the election was $10676$ during the first round (with $53383$ votes) and $32685$ during the second round (with $163425$ votes). Between May and October 2021 the process will be repeated to select the candidate who will run for the 2022 presidential elections \citep{LaPrimaire2022}.

The procedure that they adopted consists of two rounds. In the first round each voter is asked to express her judgment, using \acs{MJ}, on five random candidates. At the end of this phase the five candidates with the highest medians are considered the finalists who qualify for the second round. In the second round each voter is asked to express her judgment, using \acs{MJ}, on all the five finalists. The candidate with the best median at the end of this phase is selected as representative for the presidential election.

In this paper we analyse this elicitation process of voters preferences. In particular, we investigate the consequences of randomness when asking the voters to judge candidates. We then search for more efficient techniques both in terms of communication cost \textemdash which can be quantified as number of questions per voter \textemdash and of fairness for candidates \textemdash which reflects the idea that a potential winner should not loose for lack of information.


\subsection{Related work}

To the best of our knowledge there are no works on elicitation of voter preferences under \acs{MJ}.

Several authors studied the strengths and the weakness of this method \citep{Felsenthal2008,Laslier2018} and Balinski replied to most of the critics in an article written in french published on the Revue économique \citep{Balinski2019}.

\commentBN{Add elicitation literature}

%The idea of using the median in voting is not new, the first use can be traced back to Galton's 'middlemost' \citep{Galton1907a,Galton1907b}. More recently \citet{Bassett1999} proposed the median as a substitute for Borda's mean, advocating for its statistical robustness \textemdash which measures the sensitivity to departures from the hypothesized model. An equivalent method was proposed by James W. Bucklin in the early twentieth century \citep{Hoag1926} and it was rediscovered several times in literature for example under the names of \textit{Majoritarian Compromise} \citep{Sertel1986,Sertel1999} and \textit{Fallback Bargaining} \citep{Brams2001}. Note, also, that when the number of grades is equal to two (approve, disapprove) then \acs{MJ} is reduced to Approval Voting. 


\section{Notation}
\label{sec:complete}
Consider a finite set $N$ of voters (or judges) with $\#N=n$ and a finite set $A$ of alternatives (or competitors) with $\#A=m$. 
A \textit{common language} $\Delta = \{ \alpha, \beta, \dots \}$ is a set of strictly ordered grades. It may, or may not, be finite and the notation $\alpha \geq \beta$ indicates that $\alpha$ is a better or equivalent grade than $\beta$. A profile $P = P(A,N) = \Delta^{m \times n}$ is a $m$ by $n$ matrix of grades. The operator $\rho: \Delta^{n} \rightarrow \Delta^n$ defines an ordering function that given a vector of grades $P_i$ returns the vector ordered by decreasing grades.

Consider a set of alternatives $S\subseteq A$ where $|S|=s$ and $s \in \intvl{1,m}$ \textemdash the double brackets represent an interval in the integers. We denote by $P^S$ a restriction of the profile $P$ to only the alternatives in $S$. Note that when $S=A$ then $P^S=P$.

Given any $s \in \intvl{1,m}$, a grading function $f^s: \Delta^{s \times n} \rightarrow \Delta^s$ is a function that assigns to a profile $P^S$ a vector of final grades, one for each alternative. A social grading function (SGF) is a grading function that is neutral, anonymous, unanimous, monotonic, independent of irrelevant alternatives (IIA) and continuous. 
% the \emph{middlemost} aggregation function $f$, for each vector of grades $r_i= (r_1 , \dots, r_n )$ associated to the alternative $i \in \intvl{1,m}$, returns: 
%\begin{align}
%	f(r_i) &= r_{(n+1)/2} \text{ when n is odd,} \\
%	r_{n/2} \geq f(r_i) &\geq r_{(n+2)/2} \text{ otherwise.}
%\end{align}
The \emph{majority-grade}, $f^s_{maj}$, is a SGF that associates to a profile $P^S$ a vector of median grade values, one for each alternative: $f^s_{maj}(P^S)_i = \rho(P^S_i)_{\lfloor \frac{n}{2} \rfloor + 1}$, $\forall i \in S$. In other words, the $i$-\emph{th} element of the resulting vector is the median of the ordered vector of grades associated to the alternative $i$. Observe that as $f^s_{maj}$ is IIA, $f^s_{maj}(P^S)_i$ must depend only on $P^S_i$ so we write $f^s_{maj}(P^S_i)$. Moreover, when we consider the complete profile (when $S=A$) we will write $f_{maj}(P_i)$ instead of $f^m_{maj}(P^A_i)$.
%i.e. it corresponds to the lower middlemost.

Given any $s \in \intvl{1,m}$, the winner function $F^s:\Delta^{s} \rightarrow W \subseteq A$ is a function that selects the alternatives with the highest median grades as winners: $F^s(P^S) = \argmax_{i\in S}\rho(P^S_i)_{\lfloor \frac{n}{2} \rfloor + 1}$.
Let $h$ denote the highest median grade, $h=\max_{i\in S}\rho(P^S_i)_{\lfloor \frac{n}{2} \rfloor + 1}$, and consider the case where two, or more, alternatives are selected as winners \textemdash i.e. candidates with the same highest median grade $h$. We break ties by removing one $h$ grade from the vectors of grades of each tied alternative, recomputing the new median grade and repeating the process until one unique winner is found or there are no more grades to remove. Please note that in case two, or more, alternatives are associated with the same vector of grades the procedure does not define an unique winner. We denote by $F^s_{maj}$ the winner function after having applied the aforementioned tie-breaking procedure and, for brevity, we will write $F_{maj}$ when considering $S=A$.

Similarly to the winner function, given any $s,q \in \intvl{1,m}$, we can define a more general \emph{selection function} $F^s_q:\Delta^{s} \rightarrow Q \subseteq A$ that selects exactly $q$ alternatives with the $q$ highest median grades. Please note that, even using the tie-breaking procedure, we have no guarantee that $|Q|=q$. In order to enforce this condition we add a last step to the procedure: if ties cannot be broken the candidates are randomly chosen among the tied ones to complete the set of $q$. 

\subsection{Incomplete Knowledge}
In order to analyse the elicitation procedure used by LaPrimaire.org, we need to adapt the notation just described to incomplete profiles. Let $\bar{P}$ be our knowledge about the profile $P$.
The voters have full knowledge of their own judgments but we ignore them; our goal is to elicit them by questioning the voters starting from zero knowledge.
We introduce an additional \emph{Undefined} grade, $\bar{\Delta}=\Delta \cup \{\textit{Undefined}\}$. Voters cannot use this grade to express their judgment over an alternative and it does not count in the computation of the median grade. We refer to the grades in $\Delta$, the ones used by voters, as "defined" grades.

The starting knowledge is represented by a matrix $m\times n$ of \textit{Undefined} grades. We define with $K_j \in A$ a set of $k$ alternatives that we ask the voter $j\in N$ to judge. After having asked every voter in $N$ to judge $k$ candidates, we obtain an \emph{incomplete profile} $\bar{P^k}$, that is a matrix $m \times n$ of grades of which $k \times n$ are "defined". Note that when $k=n$ the resulting profile $\bar{P^k}$ corresponds to the complete profile $P$. Let $C(\bar{P^k}) = \{P' \in \Delta^{m \times n} | \bar{P^k} \subseteq P'\}$ be the set of all completions of $\bar{P^k}$ obtained by substituting all \emph{Undefined} grades with "defined" ones, then $P \in C(\bar{P^k})$.

If $K_j=K_l, \ \forall j,l\in N$, i.e. if we ask all voters to judge the same $k$ alternatives, then we have complete knowledge restricted to this set of candidates $K \subseteq A$. As defined in \Cref{sec:complete}, we call $P^{K}$ the restriction of the complete profile $P$ to only the alternatives in $K$.

%%%% First definition: I define a function that gives me the number of defined grades %%%%
%Let $d:\Delta^{n}\rightarrow \N$ be a function that given an incomplete vector of grades returns the number of "defined" grades of the vector: $d(\bar{P_i})=n-\#$\emph{Undefined}. \commentBN{With $\#$\emph{Undefined} I mean the number of Undefined grades.}

Let $d:\Delta^{n}\rightarrow \Delta^{x}$, where $x \in \intvl{1,n}$, be a function that given an incomplete vector of grades returns the vector composed only of the $x$ "defined" grades. \commentBN{I'm not sure this is the most correct way of defining it, because x changes depending on the vector.}
%Given a vector $\bar{P_i}$ the number of the elements of the correspondent vector $d(\bar{P_i})$ can be view as $|d(\bar{P_i})|=n-\#\{$\emph{Undefined}$\}_i$. \commentBN{I struggle a lot to define this but maybe it's useless.}

The operator $\bar{\rho}$ defines a restricting ordering function that given $\bar{P_i}$, an incomplete vector of $n$ grades, returns the correspondent complete vector restricted to its $x$ "defined" grades decreasingly ordered: $\bar{\rho}(\bar{P_i})=\rho(d(\bar{P_i}))$. \commentBN{Not sure this is necessary.}

Given any $s \in \intvl{1,m}$, the \emph{majority-grade} for incomplete profile $\bar{f}^s_{maj}: \Delta^{s \times n} \rightarrow \Delta^s$ corresponds to $f^s_{maj}$ that only considers the "defined" grades in the computation of the median: $\bar{f}^s_{maj}(\bar{P^S})_i = \rho(d(\bar{P^S_i}))_{\lfloor \frac{x}{2} \rfloor + 1}$, $\forall i \in S$. \commentBN{Here it's the problem, what is x?} 

To summarize, starting with zero knowledge, we ask the voters to judge $k$ candidates. Given the partial information at our disposal, we are able to define the "known" median grade for each alternative. We can now use the \emph{selection function} $F^s_k:\Delta^s \rightarrow \tilde{K} \subseteq A$, defined in \Cref{sec:complete}, to select the $k$ alternatives with the highest "known" median grades.

Given the set $\tilde{K}$ of the "best" $k$ alternatives, every voter is then asked to judge all the candidates in $\tilde{K}$. This process results in a restriction $P^{\tilde{K}}$ of the complete profile $P$. It is important to mention that when we ask the voters to judge an alternative $i\in \tilde{K}$ we assume that they report their preference as they would have stated it when asked about $P$. In other words, $P^{\tilde{K}}_{i} = P_i$ for any $i \in \tilde{K}$.

Please note that $P^{\tilde{K}}$ is a complete matrix of $k \times n$ grades and that we fall back to the complete profile case, thus, we apply the \emph{majority-grade}, $f^k_{maj}$, function to $P^{\tilde{K}}$ to determine the median grades and then the winner function $F^k_{maj}$ to select the winners. For simplicity we denote by $\bar{W}_{\bar{P^k}} \subseteq A$ the results of this process.

\begin{remark}
	Because we are interested into investigating \acs{MJ}, we are going to use the same alphabet of grades proposed by \citet{Balinski2011} composed of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be Rejected. Therefore, $\Delta=\{$E, VG, G, A, M, I, TbR$\}$ 
\end{remark}

Once having defined the notation, the first question that comes to mind is about the risks of incomplete knowledge. Assuming there exists a profile which we only partially know, would we always select the same set of alternatives as winners in case of complete and incomplete knowledge?

\begin{proposition}
	\label{prop:notsamewinner}
	Given $A$ the set of $m\geq 3$ alternatives, $N$ the set of $n\geq3$ voters and any integer $k \in \intvl{1,m-1}$, there exist a complete profile $P$ and an incomplete profile $\bar{P^k} \subset P$, such that $F_{maj}(P) \nsubseteq \bar{W}_{\bar{P^k}}$.
\end{proposition}
\begin{proof}
	Pick an alternative $i\in A$ and a voter $j \in N$, let us build a profile $P$ in the following way: the voter $j$ judges \textit{To be Rejected} the alternative $i$ and she judges \textit{Inadequate} all the other alternatives $x \in A \setminus \{i\}$; every other voter $y\in N \setminus \{j\}$ judges \textit{Excellent} the alternative $i$ and \textit{Very Good} all the other alternatives $x \in A \setminus \{i\}$. The resulting profile $P$ will have the form:
	\begin{center}
		$
		\begin{array}{ccccccc}
			& j_1 & j_2 & \dots & j & \dots & j_n \\
			i_1 &	VG & VG & \dots & I & \dots & VG \\
			i_2 &	VG & VG & \dots & I & \dots & VG \\
			. &	VG & VG & \dots & I & \dots & VG \\
			i &	E & E & \dots & TbR & \dots & E \\
			. &	VG & VG & \dots & I & \dots & VG \\
			i_m &	VG & VG & \dots & I & \dots & VG \\
		\end{array} \quad.
		$
	\end{center}
	For $n\geq 3$ the median grade $f_{maj}(P_i)=$\textit{Excellent} and $f_{maj}(P_x)=$\textit{Very Good} $\forall x \in A \setminus \{i\}$. Thus, the set of winner $F_{maj}(P)=\{i\}$.
	
	Consider now any $k \in \intvl{1,m-1}$, and remove from $P$ as many judgments as necessary such that the following conditions are verified: each column only contains $k$ grades \textemdash meaning that each voter judges $k$ candidates \textemdash and the row corresponding to the alternative $i$ is only formed by two grades, one \textit{Excellent} and one \textit{To be Rejected} \textemdash we have only the best and worst opinion on $i$. We fill all the unknown judgments with \textit{Undefined} grades to obtain $\bar{P^k}$. Note that we only have two judgments for the alternative $i$ so $\bar{f}_{maj}(\bar{P^k}_i)=$\textit{To be Rejected} and, since $m\geq3$ and $1 \leq k \leq m-1$, $\bar{f}_{maj}(\bar{P^k}_x)$ is either \textit{Very Good} or \textit{Inadequate} $\forall x \in A \setminus \{i\}$. Therefore $\bar{f}_{maj}(\bar{P^k}_x) > \bar{f}_{maj}(\bar{P^k}_i)$ $\forall x \in A \setminus \{i\}$, this means that $i$ will not be selected for the second turn, when we ask the voters their complete preferences about the $k$ "best" alternatives. Thus $i \notin \bar{W}_{\bar{P^k}}$ and, consequently, $F_{maj}(P) \nsubseteq \bar{W}_{\bar{P^k}}$.
\end{proof}


\section{Reasoning on incompleteness}
Let us denote by $W^*=F_{maj}(P)$ the set of winners associated to the complete profile $P$, and recall that $\bar{W}_{\bar{P^k}}$ indicates the set of winners associated to the incomplete profile $\bar{P^k}$.

As we observed in \Cref{prop:notsamewinner}, given an incomplete profile $\bar{P^k} \subset P$ it is possible to elect a candidate as a winner that would not be selected when considering (one of) its completion $P \in C(\bar{P^k})$. In this section we want to investigate how likely it is to happen.

Assume that the complete profile $P$ exists but it is unknown to us, the knowledge we have is represented by $\bar{P^k}$ and the voters are truthful. This means that starting from $\bar{P^k}$, by asking each voter to judge every alternative we converge to $P$.

Consider an alternative $w\in A$ and observe that for $w$ to be in $W^*$ then $f_{maj}(P_w)\geq f_{maj}(P_i), \ \forall i \in A$. Consider now the incomplete profile $\bar{P^k}$ and the set of the $k$ alternatives with the highest "known" median grades $\tilde{K}$. Let $v$ be the $k$-th highest median, i.e. $v=\min_{i\in \tilde{K}} \bar{f}_{maj}(\bar{P_i})$ the lowest grade of an alternative in $\tilde{K}$. If $\bar{f}_{maj}(\bar{P}_w) \geq v$ then $w \in \tilde{K}$. 

Because the voters express their judgments on all the alternatives in $\tilde{K}$ and $P^{\tilde{K}}_{i} = P_i$ for any $i \in \tilde{K}$, then if $w \in W^*$ and $w \in \tilde{K}$ then $w \in \bar{W}_{\bar{P^k}}$.

In order to compute the probability of a winning alternative $w$ to not be elected in case of incompleteness, we need to focus on the probability for $w$ not to reach the second round: probability of $w \notin \tilde{K}$.

Consider the complete profile $P$ and the highest median grade $h=\max_{i\in A}\rho(P_i)_{\lfloor \frac{n}{2} \rfloor + 1}$. Since $w \in W^*$ then $f_{maj}(P_{w})\geq h$ and the vector of grades $P_w$ must be composed of at least $\lfloor \frac{n}{2}\rfloor+1$ grades $\alpha \geq h$ and at most $\lceil \frac{n}{2}\rceil-1$ of grades $\beta < h$. Let us evaluate the worst case scenario.
Without loss of generality consider $n$ an odd value, then the vector $P_{w}$ in the worst case contains exactly $\frac{n+1}{2}$ grades greater than or equal to $h$ and $\frac{n-1}{2}$ grades lower than $h$.
\[P_w : \qquad [ \alpha_1, \dots , \alpha_{\frac{n+1}{2}}, \beta_1, \dots , \beta_{\frac{n-1}{2}} ] \]
Consider now the incomplete profile $\bar{P^k} \subset P$ and the highest "known" median $v$ described above. For $w \notin \tilde{K}$ then $\bar{f}_{maj}(\bar{P^k}_w) < v$ and the partial vector $\bar{P^k}_w$ of $x\in \intvl{1,n-1}$ defined grades must be composed of at least $\frac{x+1}{2}$ grades $\beta'<v$ and at most $\frac{x-1}{2}$ grades $\alpha' \geq v$. 

If $h=v$, we have $\binom{(n+1)/2}{(x-1)/2}$ ways of picking $\frac{x-1}{2}$ grades greater than or equal to $v$ out of the $\frac{n+1}{2}$ of the original vector; and $\binom{(n-1)/2}{(x+1)/2}$ ways of picking $\frac{x+1}{2}$ grades lower than $v$.
\begin{align}
	P_{w}: \qquad [ \underbrace{\alpha_1, \dots , \alpha_{\frac{n+1}{2}}}_{\begin{pmatrix}\frac{n+1}{2} \\ \frac{x-1}{2}\end{pmatrix}}, \underbrace{\beta_1, \dots , \beta_{\frac{n-1}{2}}}_{\begin{pmatrix}\frac{n-1}{2} \\ {\frac{x+1}{2}}\end{pmatrix}} ] \\
	\bar{P^k}_w:\qquad [ \overbrace{\alpha'_1, \dots , \alpha'_{\frac{x-1}{2}}}, \overbrace{\beta'_1, \dots , \beta'_{\frac{x+1}{2}}}]
\end{align} 
\newcommand{\largemath}[1]{{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\mathlarger#1}}}}}}
%note to myself: find a better way please

We define the probability of $w \notin \tilde{K}$ as the number of incomplete vectors $\bar{P^k}_w$ for which $\bar{f}_{maj}(\bar{P^k}_w) < v$, over the total number of possible incomplete vectors:
\[ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n+1}{2} \\ {\frac{x-1}{2}-i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n-1}{2} \\ {\frac{x+1}{2}+i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} } \]

\commentBN{resume from here}

The size $x$ of an incomplete vector $\bar{P_i}$ for $i \in A$, depends on the number of questions $k$ asked to the voters, in fact, if we ask $n$ voters to judge $k$ random alternatives, ideally, each alternative $i$ will be judged $\frac{k\cdot n}{m}$ times. Consider the value $k$ as a function of the number of alternatives: $k=c \cdot m$ where $c \in \R$. If $m=10$ and $k=5$ then $k=1/2 m$, i.e. we ask the voters to judge half of the candidates. Thus, the value $x$ depends only on the number of voters $n$ $x=\frac{k\cdot n}{m}= c \cdot n$, $c\in \R$. Without loss of generality we consider both $x$ and $n$ odd values.

Consider the worst case scenario: the real vector $P_{w^*}$ has a proportion of $51\%-49\%$ of $\alpha-\beta$ grades. \Cref{fig:differentX51-49} shows the probability of electing a non-real winner in this scenario for different size $x$ of the incomplete vector $\bar{P_{w^*}}$. \Cref{tab:differentX51-49} shows in details those values. Note that when $x=1001$ the probability is about $25\%$, but we should keep in mind that $x= c \cdot n$, thus a vector of size $1000$ means that the alternative $w^*$ was judged by only $1/10$ of the voters. With this in mind, we see that with $x=\frac{n}{2}$ we obtain a very low probability of only $2.12\%$, but we need $4/5$ of the voters to judge each alternative to get zero probability of "miss-qualification".

The situation change drastically for different proportions of $\alpha-\beta$ grades as \Cref{fig:differentX} shows. In particular, we only need about $200$ judgments (thus $1/50$n) to reach an almost zero probability of electing a non real winner when the real vector $P_{w^*}$ has a proportion of $60\% \alpha -40\% \beta$ grades. Recalling the formula:
\begin{align}
	x&=\frac{k \cdot n}{m} \\
	200&=\frac{k}{m}\cdot 10000 \\
	\frac{1}{50}&=\frac{k}{m} \\
	k&=\frac{m}{50}
\end{align}
we note that asking one question per voter is more than enough to avoid the election of a non-real winner.

In the 2016 elections organised by LaPrimaire.org $n=10675$ voters participated in the first round, and each of them judged $k=5$ random alternatives out of the $m=12$ total ones. Each alternative received an average of $4449$ judgments. Using this data, we simulated th probability of electing a non-real winner for different proportions of $\alpha-\beta$ grades. \Cref{fig:original} and \Cref{tab:original} show the results.

By crossing these results we note that we could have asked the voters far less than $5$ questions, reducing the communication and the cognitive cost of the elicitation process.

%xticklabel style = {font=\footnotesize},
%x label style={at={(axis description cs:0.5,-0.05)},anchor=north}
\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ylabel=Prob. \%,
			xlabel= x,
			ymin=0,
			ymax=50,
			xmin=1,
			xmax=10001,
			xtick={1,1001,2001,3001,4001,5001,6001,7001,8001,9001,10001},
			xticklabels={$10^{-3}$,1,2,3,4,5,6,7,8,9,10},
			xticklabel style = {yshift=-0.5ex},
			scaled x ticks= real:1000,
			x label style={at={(axis description cs:0.5,-0.03)},anchor=north}
			]
			\addplot[thick, blue] table [x=x, y=ProbOfMiss, col sep=comma]{data/51-49-100.csv};			
		\end{axis}
	\end{tikzpicture}
	\caption{Probability of electing a non-real winner, for different values of $x$, with $n=10000$, and $51\%-49\%$ proportion of $\alpha - \beta$ grades.}
	\label{fig:differentX51-49}
\end{figure}

\sisetup{table-number-alignment = center, table-figures-integer=2, table-figures-decimal=1, table-auto-round}
\begin{table}
	\centering
	\begin{tabular}{S[table-figures-integer=5, table-figures-decimal=0]S[table-figures-integer=2, table-figures-decimal=2]}
			\toprule
			{x} & {Prob. of Miss} \\
			\midrule
			1	&	48.9853044087	\\
			1001	&	24.9190117413	\\
			2001	&	15.5009678852	\\
			3001	&	9.1920240364	\\
			4001	&	4.8710050444	\\
			5001	&	2.1180123415	\\
			6001	&	0.645530701	\\
			7001	&	0.096388706	\\
			8001	&	0.0024354987	\\
			9001	&	0.000000051	\\
			10001	&	0.00	\\
			\bottomrule
		\end{tabular}
	\caption{Detailed numbers of \Cref{fig:differentX51-49}.}
	\label{tab:differentX51-49}
\end{table}

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ylabel=Prob. \%,
			xlabel= x,
			ymin=0,
			ymax=50,
			xmin=1,
			xmax=201,
			enlarge x limits=-1, %hack to plot on the full x-axis scale
			width=13cm, %set bigger width
			height=6cm,
			legend style={font=\scriptsize}
			]
			\addlegendimage{mark=*,teal,mark size=1.5}
			\addlegendimage{mark=triangle*,orange,mark size=1.5}
			\addlegendimage{mark=square*,blue,mark size=1.5}
			\addlegendimage{mark=diamond*,red,mark size=1.5}
			
			\addplot[thick, mark=*, mark size = {2}, mark indices = {15}, teal] table [x=x, y=ProbOfMiss, col sep=comma]{data/60-40-2.csv};
			\addlegendentry{$60\%-40\%$}
			\addplot[thick, mark=triangle*, mark size = {2}, mark indices = {6}, orange] table [x=x, y=ProbOfMiss, col sep=comma]{data/70-30-2.csv};
			\addlegendentry{$70\%-30\%$}	
			\addplot[thick, mark=square*, mark size = {2}, mark indices = {4}, blue] table [x=x, y=ProbOfMiss, col sep=comma]{data/80-20-2.csv};	
			\addlegendentry{$80\%-20\%$}
			\addplot[thick, mark=diamond*, mark size = {2}, mark indices = {2}, red] table [x=x, y=ProbOfMiss, col sep=comma]{data/90-10-2.csv};			
			\addlegendentry{$90\%-10\%$}
		\end{axis}
	\end{tikzpicture}
	\caption{Probability of electing a non-real winner, for different values of $x$ and different proportion of $\alpha - \beta$ grades, with $n=10000$.}
	\label{fig:differentX}
\end{figure}


\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ylabel=Prob. of Miss \%,
			xlabel=Percentage of $\alpha$ Grades \%,
			ymin=0,
			ymax=5,
			xmin=5445,
			xmax=9608,
			scaled ticks = false,
			xtick={5445,6405,7473,8540,9608},
			xticklabels={51,60,70,80,90}
			]
			\addplot[thick, red] table [x=BetterThanMed, y=ProbOfMiss, col sep=comma]{data/original.csv};			
		\end{axis}
	\end{tikzpicture}
	\caption{Probability of electing a non-real winner, for $n=10675$, $x=4449$ and different proportion of $\alpha - \beta$ grades.}
	\label{fig:original}
\end{figure}

\begin{table}
	\centering
	\begin{tabular}{cc}
		\toprule
		{$\alpha-\beta$} & {Prob. of Miss} \\
		\midrule
		$51\%-49\%$	&	3.92	\\
		$60\%-40\%$	&	2.79$10^{-69}$	\\
		$70\%-30\%$	&	5.80$10^{-318}$	\\
		$80\%-20\%$	&	0.00	\\
		$90\%-10\%$	&	0.00	\\
		\bottomrule
	\end{tabular}
	\caption{Detailed numbers of \Cref{fig:original}.}
	\label{tab:original}
\end{table}

\subsection{Unfixed k}

A natural question that comes to mind when considering the process of asking the voters to judge random alternatives is: how feasible is it? Especially when applying it to political elections, it is safe to say that voters have strong opinions. There are always some candidates that we would never want to see in office, while we would really like to support our favorite candidate. By applying the random selection of questions there is a chance we do not get to express our opinions on those particular candidates. In the worst case, we may be asked to judge only candidates of whom we do not have a strong opinion, or worse, that we do not even know. Is our judgment relevant in this case? How willing are we to take the risk to go and vote without the certainty of being able to express the judgments we consider important?

Because of all these reasons, we may want to consider the possibility for the voters to choose the candidates to judge. One extreme situation that may occur is that each voter judges only its best and worst choice. 

\begin{proposition}
	Given two integers $k=5$ and $s=5$, $m$ alternatives and $n$ voters who only judge their best and worst candidates, there exist a complete profile $P'$ and an incomplete profile $\bar{P'}$ such that $P'\in C(\bar{P'})$ and $F(P')\neq F(\bar{P'})$.
\end{proposition}	

\begin{proof} Consider the following complete profile $P$:

	\begin{center}
		\begin{tabular}{cccccccc}
			& j$_1$ & j$_2$ & j$_3$ \\
			a	&	Average	&	Average	&	Excellent	\\
			b	&	To be rejected	&	Good	&	Good	\\
			c	&	Mediocre	&	Excellent	&	Mediocre	\\
			d	&	Average	&	Average	&	To be rejected	\\
			e	&	Mediocre	&	To be rejected	&	Mediocre	\\
			f	&	Excellent	&	Inadequate	&	Inadequate \\
		\end{tabular}
	\end{center}
	
	
	for the sake of the example the rows are not ordered vectors because the identity of the voters is considered.
	
	The vector of medians $f_{maj}(P)$ is:
	\begin{center}
		$
		\begin{array}{cc}
			a &	Average \\
			b &	Good \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Inadequate \\
		\end{array} \quad.
		$
	\end{center}
	The real winner is $F^P=b$. 
	
	Assume that each voter only express its best and worst judgments and construct the complete profile $P'$ from $P$ in the following way: for each alternative $i$ that is not the real winner $w^*$ add as many voters as needed such that its known median grade ($f_{maj}(\bar{P'_i})$) is better than the known median grade of the real winner ($f_{maj}(\bar{P'_{w^*}})$); then add an additional alternative that is rejected by all these new voters. Since the voters only express the best and the worst grades, we are not interested in how they judge the rest of the alternatives, to construct a complete profile we can assume that they judge them according to the current known median. The resulting complete profile $P'$ is the following, but our information $\bar{P'}$ is only restricted to the green values: 

		\scalebox{0.75}{
			\begin{tabular}{cccccccc}
				& j$_1$ & j$_2$ & j$_3$ & j$_4$ & j$_5$ & j$_6$ & j$_7$ \\
				a	&	Average	&	Average	&	{\color{teal}Excellent}	&	Average	&	Average	&	Average	&	Average	\\
				b	&	{\color{teal}To be rejected}	&	Good	&	Good	&	Good	&	Good	&	Good	&	Good	\\
				c	&	Mediocre	&	{\color{teal}Excellent}	&	Mediocre	&	Mediocre	&	Mediocre	&	Mediocre	&	Mediocre	\\
				d	&	Average	&	Average	&	{\color{teal}To be rejected}	&	{\color{teal}Excellent}	&	{\color{teal}Excellent}	&	Average	&	Average	\\
				e	&	Mediocre	&	{\color{teal}To be rejected}	&	Mediocre	&	Mediocre	&	Mediocre	&	{\color{teal}Excellent}	&	{\color{teal}Excellent}	\\
				f	&	{\color{teal}Excellent}	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	\\
				g	&	{\color{teal}To be rejected}	&	{\color{teal}To be rejected} & {\color{teal}To be rejected}& {\color{teal}To be rejected} & {\color{teal}To be rejected} & {\color{teal}To be rejected} & {\color{teal}To be rejected}	\\
			\end{tabular}
		}
		
	The vector of medians $f_{maj}(\bar{P'})$ is:
	\begin{center}
		$
		\begin{array}{cc}
			a &	\text{Excellent} \\
			b &	\text{To be rejected} \\
			c &	\text{Excellent} \\
			d &	\text{Excellent}	\\
			e &	\text{Excellent} \\
			f & \text{Excellent} \\
			g & \text{To be rejected} \\
		\end{array} \quad.
		$
	\end{center}
	The real winner $b$ does not appear in the set of candidates for the second round $S=\{a,c,d,e,f\}$, so it will not be elected from the incomplete profile $\bar{P'}$.
\end{proof}
	



\newpage
\paragraph{My draft - do not read}
\begin{itemize}
	\item Does expressing judgment on randomly selected candidates influence the result? (If we change the questions does the result change?)
	\item Does the number of questions influence the result? (If we change the number of questions does the result change?)
	\item If yes, do these effects are mitigated by a second round?
	\item Which is the right number of questions? (Best trade-off between communication cost and optimal result.)
	\item Can we select the next question with minimax regret instead of randomly selecting a candidate?
	\item Can we say anything about the "fairness" of proposing the candidates to judge? Suppose I have strong opinions about only two candidates: one I extremely like and one I extremely dislike. There is a chance I will not be asked about those two candidates, in this case I cannot say much about the other candidates and I am also frustrated because I did not get to express my opinions.
	\item Consider $n$ voters and $m$ candidates and assume that a voter $i \in N$ judges only a fraction of the $m$ candidates. What is the resulting voting rule? What are its properties? Can a voter manipulate the result by judging only some candidates? 
\end{itemize}

\newpage
\bibliography{biblio}
\newpage
\appendix
\section{Old material that can be transformed into examples}
\begin{proof} Consider $n=3, m=6, k=5$ and the following complete profile $P$:
	\begin{center}
		$
		\begin{array}{cccc}
			& j_1 & j_2 & j_3 \\
			a &	Excellent	& Excellent & Inadequate\\
			b &	Mediocre	& Mediocre	& Mediocre\\
			c &	Mediocre	& Mediocre & Inadequate\\
			d &	Average	& Average	& Average\\
			e &	Average	& Mediocre	& Inadequate \\
			f &	Average	& Mediocre & Mediocre	  \\
		\end{array} \quad.
		$
	\end{center}
	The vector of medians $f_{maj}(P)$ is:
	\begin{center}
		$
		\begin{array}{cc}
			a &	Excellent \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Mediocre \\
		\end{array} \quad.
		$
	\end{center}
	The real winner is $F^P=a$. 
	
	Consider now the following incomplete profiles $\bar{P}$ and $\bar{P}'$ obtained after having asked each voter to judge $k=5$ random chosen alternatives: \commentOC{This mixes again the process and the maths. The proposition does not talk about randomness and it is confusing to refer to this here. The proposition holds whatever the way $P$ bar is chosen (including, deterministically).}\commentBN{I'm not sure I got this. With randomness I mean the one in the definition of $\bar{P}$.}
	\begin{center}
		$\bar{P}: \qquad
		\begin{array}{cccc}
			& j_1 & j_2 & j_3 \\
			a &	Excellent	& {\color{red}Undefined} & Inadequate\\
			b &	Mediocre	& Mediocre	& Mediocre\\
			c &	Mediocre	& Mediocre & Inadequate\\
			d &	Average	& Average	& {\color{red}Undefined} \\
			e &	Average	& Mediocre	& Inadequate \\
			f &	{\color{red}Undefined}	& Mediocre & Mediocre	  \\
		\end{array} \quad,
		$
	\end{center}
	\begin{center}
		$\bar{P}': \qquad
		\begin{array}{cccc}
			& j_1 & j_2 & j_3 \\
			a &	Excellent	& Excellent & Inadequate\\
			b &	Mediocre	& {\color{red}Undefined}	& Mediocre\\
			c &	Mediocre	& Mediocre & {\color{red}Undefined}\\
			d &	Average	& Average	& Average \\
			e &	{\color{red}Undefined}	& Mediocre	& Inadequate \\
			f &	Average	& Mediocre & Mediocre	  \\
		\end{array} \quad.
		$
	\end{center}
	The vector of medians are:
	\begin{center}
		$f_{maj}(\bar{P})= \quad
		\begin{array}{cc}
			a &	Inadequate \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Mediocre \\
		\end{array} \quad,\quad%
		f_{maj}(\bar{P}')= \quad
		\begin{array}{cc}
			a &	Excellent \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Inadequate \\
			f & Mediocre \\
		\end{array} \quad.
		$
	\end{center}
	
	Consider the sets of $s=5$ alternatives with the highest median grades for the two profiles, $S'=\{b,c,d,e,f\}$ for $\bar{P}$, and $S^{\prime\prime}=\{a,b,c,d,f\}$ for $\bar{P}'$, and the two restrictions $P_{S'}$ and $P_{S^{\prime\prime}}$. In particular, $P_{S'}$ corresponds to the complete profile when eliminating the alternative $a$, and $P_{S^{\prime\prime}}$ to the complete profile without the alternative $e$.
	The vector of medians are:
	\begin{center}
		$f_{maj}(P_S')= \quad
		\begin{array}{cc}
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Mediocre \\
		\end{array} \quad,\quad%
		f_{maj}(P_S^{\prime\prime})= \quad
		\begin{array}{cc}
			a & Excellent \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			f & Mediocre \\
		\end{array} \quad.
		$
	\end{center}
	The winner associated to the incomplete profile $\bar{P}$ is then $F^{P_{S'}} = d$ and the one associated to $\bar{P}'$ is $F^{P_{S^{\prime\prime}}} = a$, thus $F^{\bar{P}} \neq F^{\bar{P}'}$.
\end{proof}
\commentOC{Perhaps some part of this could be transformed to an example.}

\begin{corollary}
	Given $m$ alternatives, $n$ voters and an integer $k \in \intvl{1,m}$, there exist a profile $P$ and an incomplete profile of $P$, $\bar{P}$, such that $F^{\bar{P}}$ is not the real winner.
\end{corollary}
\commentOC{“real winner” is inappropriate here. Is there an unreal winner? I realize that you mean “winner considering the complete profile” VS “winner considering some part of it”, but I don’t think that the term “real” is appropriate. I’d simply say “winners” for the winners of the complete election, and perhaps “approximate winners” for the winners given a partial profile, or something similar.}

\end{document}

