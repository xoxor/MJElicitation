\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}
%\input{preamble/draw}
%\input{preamble/jdoc}
\usepackage{stmaryrd}
\usepackage{xcolor}
\usepackage{siunitx}
\usepackage{relsize}
\pgfplotsset{compat=1.17}
%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Preference Elicitation under Majority Judgment}
\author{}
%\title{The title \thanks{Thanks.}}
%\author{Olivier Cailloux}
%\author{Name2}
%\affil{Université Paris-Dauphine, Université PSL, CNRS, LAMSADE, 75016 PARIS, FRANCE\\
%	\href{mailto:olivier.cailloux@dauphine.fr}{olivier.cailloux@dauphine.fr}
%}
%\author{Name3}
%\affil{Affil2}
%\hypersetup{
%	pdfsubject={},
%	pdfkeywords={},
%}

\begin{document}
\maketitle

\begin{abstract}
\acl{MJ} (\acs{MJ}) is a voting system where voters assign grades to candidates using an ordinal scale. The winner is the candidate with the highest majority-grade \textemdash which is the median of the grades received. This method has attracted increasing attention of french associations and political parties which have started to use \acs{MJ} for internal decisions or local elections. In particular LaPrimaire.org is a french association that uses \acs{MJ} to choose its candidate for the french presidential election. The vote is conducted in two rounds: in the first one the voters judge five candidates randomly picked; the five candidates with the highest medians pass at the second round as finalists and the voters are asked to judge them. Is the random selection of candidates a good elicitation technique? In this paper we explore the consequences of profile incompleteness and we question the elicitation of voters preferences.
\end{abstract}

\section{Introduction}
\label{sec:intro}
\acl{MJ} (\acs{MJ}) is a voting method proposed by \citet{Balinski2007,Balinski2011} to elect one out of $m$ candidates based on the judgments of $n$ voters. The latter express their preferences by assigning to each candidate one of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be rejected. Those adjectives represent a common language whose semantic is assumed to be a shared knowledge among the voters carrying thus an absolute meaning. For each candidate the median of the grades she received is computed, this is called \textit{majority-grade}. The candidate with the highest majority-grade is elected. Ties are broken by considering the majority-grade of first order: one vote associated with the majority-grade of each tied candidates is removed and their medians are recomputed. The candidate with the highest new median is elected. If there is still a tie the process is repeated until a unique winner is found. 

In the last few years \acs{MJ} has being adopted by a progressively larger number of french political parties including: Le Parti Pirate, Génération(s), LaPrimaire.org, France Insoumise and La République en Marche.
%https://www.lopinion.fr/edition/politique/en-marche-teste-elections-jugement-majoritaire-mode-scrutin-tres-201884
"Mieux Voter" \citep{MV} is a french association that promotes the use of \acs{MJ} as voting method whenever a collective choice has to be selected: public administration, associations, companies. On their website it is possible to find all the citizens lists \textendash party lists that are not affiliated to any national political party \textemdash that used \acs{MJ} to rank their candidates during the local elections of 2020. In two cases, Bordeaux et Annecy, the candidate selected using \acs{MJ} was then elected as a mayor. 

In particular, LaPrimaire.org \citep{LaPrimaire} is a french political initiative whose goal is to select an independent candidate for the french presidential election using \acs{MJ} as voting rule. The association Democratech implemented the platform for the first time in 2016 in view of the 2017 presidential elections. The number of voters who participated in the election was $10676$ during the first round (with $53383$ votes) and $32685$ during the second round (with $163425$ votes). Between May and October 2021 the process will be repeated to select the candidate who will run for the 2022 presidential elections \citep{LaPrimaire2022}.

The procedure that they adopted consists of two rounds. In the first round each voter is asked to express her judgment, using \acs{MJ}, on five random candidates. At the end of this phase the five candidates with the highest medians are considered the finalists who qualify for the second round. In the second round each voter is asked to express her judgment, using \acs{MJ}, on all the five finalists. The candidate with the best median at the end of this phase is selected as representative for the presidential election.

In this paper we analyse this elicitation process of voters preferences. In particular, we investigate the consequences of randomness when asking the voters to judge candidates. We then search for more efficient techniques both in terms of communication cost \textemdash which can be quantified as number of questions per voter \textemdash and of fairness for candidates \textemdash which reflects the idea that a potential winner should not loose for lack of information.


\subsection{Related work}

To the best of our knowledge there are no works on elicitation of voter preferences under \acs{MJ}.

Several authors studied the strengths and the weakness of this method \citep{Felsenthal2008,Laslier2018} and Balinski replied to most of the critics in an article written in french published on the Revue économique \citep{Balinski2019}.

\commentBN{Add elicitation literature}

%The idea of using the median in voting is not new, the first use can be traced back to Galton's 'middlemost' \citep{Galton1907a,Galton1907b}. More recently \citet{Bassett1999} proposed the median as a substitute for Borda's mean, advocating for its statistical robustness \textemdash which measures the sensitivity to departures from the hypothesized model. An equivalent method was proposed by James W. Bucklin in the early twentieth century \citep{Hoag1926} and it was rediscovered several times in literature for example under the names of \textit{Majoritarian Compromise} \citep{Sertel1986,Sertel1999} and \textit{Fallback Bargaining} \citep{Brams2001}. Note, also, that when the number of grades is equal to two (approve, disapprove) then \acs{MJ} is reduced to Approval Voting. 


\section{Notation}
\label{sec:complete}
Consider a finite set $N$ of voters (or judges) with $\#N=n$ and a finite set $A$ of alternatives (or competitors) with $\#A=m$. 
A \textit{common language} $\triangle = \{ \delta_1, \delta_2, \dots \}$ is a set of strictly ordered grades. It may, or may not, be finite and the notation $\delta_1 \geq \delta_2$ indicates that $\delta_1$ is a better or equivalent grade than $\delta_2$. 
\commentOC{I think that using a symbol different that the usual comparison relation on the natural numbers (perhaps, triangle, see my template) would be most welcome, to reduce possible confusions.}\commentBN{Ok. Although now small $\delta$ makes less sense.}
A profile $P : A\times N \rightarrow \triangle$ is a $m$ by $n$ matrix of grades $P \in \triangle^{A \times N}$. The operator $\rho: \triangle^{N} \rightarrow \triangle^n$ defines an ordering function that given a vector of grades $P_i$ returns the vector ordered by decreasing grades.

Consider a set of alternatives $S\subseteq A$,
%where $|S|=s$ and $s \in \intvl{1,m}$ \textemdash the double brackets represent an interval in the integers. 
we denote by $P^S \in \triangle^{S \times N}$ a restriction of the profile $P$ to only the alternatives in $S$, $P^S \subseteq P$. Note that when $S=A$ then $P^S=P$.
%\commentOC{Could also write $\restr{P}{S × N}$, which leads to more generality, if restricting the users is also sometimes convenient.}

We define $f: \triangle^{N} \rightarrow \triangle$ a function that assigns to any vector of grades a final grade. Given any $S\subseteq A$, a grading function $f^S: \triangle^{S \times N} \rightarrow \triangle^S$ returns a vector of final grades by applying $f$ to every alternative in $S$.
A social grading function (SGF) is a grading function that is neutral, anonymous, unanimous, monotonic, independent of irrelevant alternatives (IIA) and continuous.
\commentOC{These properties should be defined briefly. 
Anonymity is built in the definition of a grading function, so I don’t think it can be defined meaningfully here.
With the current presentation I think that even IIA is built into the definition, as you require that $f^S$ applies $f$ to every alternative.
That seems too restrictive to define a meaningful class of functions (and I suppose is not what the authors mean as SGF). 
Alternatively, you could give up this part, as your paper is not mainly about how MJ compares to similar rules.}\commentBN{I agree, do I define $f$ directly a SGF ? I just wanted to be consistent with B\&L.}
% the \emph{middlemost} aggregation function $f$, for each vector of grades $r_i= (r_1 , \dots, r_n )$ associated to the alternative $i \in \intvl{1,m}$, returns: 
%\begin{align}
%	f(r_i) &= r_{(n+1)/2} \text{ when n is odd,} \\
%	r_{n/2} \geq f(r_i) &\geq r_{(n+2)/2} \text{ otherwise.}
%\end{align}

The \emph{majority-grade}, $f_{maj}$, is the function that associates to a vector of grades $q \in \triangle^{N'}, \emptyset \neq N' \subseteq N$ its median grade value: $f_{maj}(q) = \rho(q)_{\floor{\frac{|q|}{2}} + 1}$. \commentOC{Very minor, but I’d write $\emptyset ≠ q \in \Delta^N$.} \commentOC{$n$ would be clearer than $\card{q}$. But I suspect that you want to make this more general with $\emptyset \neq q \in \triangle^{N'}$ for any $N' \subseteq N$.}\commentBN{Is this better? Let's keep q until we know we don't need it.}
Given any $S\subseteq A$, by applying $f_{maj}$ to all vectors of grades associated to the alternatives in $S$ we obtain the corresponding SGF $f^S_{maj}$. Formally, $f^S_\mathit{maj}(P^S)_i = f_\mathit{maj}(P^S_i)$. The $i$-\emph{th} element of the resulting vector is the median of the ordered vector of grades associated to the $i$-\emph{th} alternative. 
%Because $f^S_{maj}(P^S)_i$ depends only on $P^S_i$ we write $f^S_{maj}(P^S_i)$. \commentOC{I am not sure I follow. You already have a notation for this, namely, $f_\mathit{maj}(P^S_i)$, isn’t it?}
Moreover, when we consider the complete profile (when $S=A$) we will write $f_{maj}(P_i)$ instead of $f^A_{maj}(P^A_i)$.
\commentOC{I doubt that the $f$ notation is actually useful, it is perhaps short enough to write what it is in full (as you do just below). At least, this mix-up between $f$ and $f^S$ should be clarified.}\commentBN{The mix-up you mean your comment just above that is now commented out?}
%i.e. it corresponds to the lower middlemost.

Given any $S\subseteq A$, the winner function $F^S_{maj}:\triangle^{S \times N} \rightarrow A$ %$F^S_{maj}:\triangle^{S \times N} \rightarrow 2^A \setminus \emptyset$
is a function that selects the alternative with the highest median grade as winner: $F^S_{maj}(P^S) = \argmax_{i\in S}\rho(P^S_i)_{\floor{\frac{n}{2}}+ 1}$. 
\commentOC{This defines in general a set of alternatives, you can’t just choose to ignore that. You must at least add “assuming it is a singleton”.}\commentBN{What if we remove this and define $F^S_{maj}$ using the ordering on the alternatives as below? }
Note that in case $n$ is even two medians could be used for an alternative, but the lower grade is picked.
\commentOC{Perhaps cite the authors again here, to emphasize that this is their choice, if this is true. This remark should come when you define the stuff that picks a median (rho, I believe).}\commentBN{I don't really see the point to emphasize it. It's already implicit in the floor no?}
Let $h$ denote the highest median grade associated to the alternatives in $S$, $h=\max_{i\in S}\rho(P^S_i)_{\floor{\frac{n}{2}} + 1}$, and consider the case where two, or more, alternatives could be selected as winners \textemdash i.e. candidates with the same highest median grade $h$. 
\commentOC{Just write “if the set blah is not a singleton, …”}
Ties are broken by removing one $h$ grade from the vectors of grades of each tied alternative, recomputing the new median grade and repeating the process until one unique winner is found or there are no more grades to remove. When $n$ is odd, this is equivalent to take the next element after the median, i.e. the one at index $(\floor{\frac{n}{2}} + 1) +1$, if there is still a tie we then look at the previous element before the median, i.e. the one at index $(\floor{\frac{n}{2}} + 1) -1$, and keep alternating until the tie is broken or there are no more elements in the vector. When $n$ is even the process is similar but we alternate starting from the element before the median, $\floor{\frac{n}{2}}$, then the one after, $\floor{\frac{n}{2}} + 2$, and so on.
\commentOC{Written as it is, I am doubtful about the value of this remark.}
\commentOC{Because of the paragraph break here, the reader may think she has missed something, as this is still not guaranteed to be a singleton and it is not immediately clear that you are still talking about the tie-breaking issue in the next paragraph.}

We denote by $>$ an ordering over the alternatives, given any set $S\subseteq A$ and any pair of candidates $i,j \in S$ we say that $i > j$ iff $f^S_{maj}(P^S_i) > f^S_{maj}(P^S_j)$ applying the tie-breaking procedure when necessary. Please note that in case $P^S_i=P^S_j$ then $f^S_{maj}(P^S_i) = f^S_{maj}(P^S_j)$ even after having applied the tie-breaking procedure, in this case we follow the lexicographical order.
\commentOC{This ordering depends on $P^S$, that’s a bit odd, it should at least be mentioned that it is used when $P^S$ is clear from the context, if this is what you mean. But do you really need this?}\commentBN{I'm not sure what you mean, should I add "Given a profile $P^S$"}
\commentOC{Lexicographical order may be unclear, it seems to me. Rather just write that an arbitrary ordering defined on all alternatives is used to break ties.}

Thus $F^S_{maj}$ can also be defined as $F^S_{maj}=i\in S$ such that $i > j, \forall j \in S \setminus \{ i \}$. 
\commentOC{I am very dubious that this makes anything clearer.}
For brevity, we will write $F_{maj}$ when considering $S=A$.

Similarly to the winner function, given any $x \in \intvl{1,m}$, we can define a more general \emph{selection function} $F^S_x:\triangle^{S\times N} \rightarrow 2^A \setminus \emptyset$ that selects exactly the $x$ alternatives with the $x$ highest median grades.
Considering that $F^S_{1}=F^S_{maj}$ we define $F^S_{x}=F^S_{x-1} \cup \{i\in S \suchthat i > j, \forall j \in S \setminus F^S_{x-1} \}$.

\subsection{Incomplete Knowledge}
In order to analyse the elicitation procedure used by LaPrimaire.org, we need to adapt the notation just described to incomplete profiles. 
\commentOC{Defining the right, full notations from the start would be more gentle for the reader.} Let $\overline{P}$ be our knowledge about the profile $P$.
The voters have full knowledge of their own judgments but we ignore them; our goal is to elicit them by questioning the voters starting from zero knowledge.
We introduce an additional \emph{Undefined} grade, $\overline{\triangle}=\triangle \cup \{\textit{Undefined}\}$. Voters cannot use this grade to express their judgment over an alternative and it does not count in the computation of the median grade as we will explain formally. We refer to the grades in $\triangle$, the ones used by voters, as "defined" grades.

The starting knowledge is represented by a matrix $m\times n$ of \textit{Undefined} grades. We define with $K_j \subseteq A$ a set of $k$ alternatives that we ask the voter $j\in N$ to judge. 
After having asked every voter in $N$ to judge $k$ candidates, we obtain an \emph{incomplete profile} $\overline{P}\in \overline{\triangle}^{A \times N}$, that is a matrix $m \times n$ of grades of which $kn$ are "defined".
Note that when $k=n$ the resulting profile $\overline{P}$ corresponds to the complete profile $P$. Let $C(\overline{P}) = \{P' \in \triangle^{m \times n} \suchthat \overline{P} \subseteq P'\}$ be the set of all completions of $\overline{P}$ obtained by substituting all \emph{Undefined} grades with "defined" ones, note that $P \in C(\overline{P})$.
\commentOC{Technically that’s not correct as $P$bar may contain some “undefined”, in which case $P$ can’t be a superset of it. (Can be left as is for now.)}
 
If $K_j=K_l, \forall j,l\in N$, i.e. \commentOC{I think that ie requires a comma afterwards, and the spacing could be improved.}\commentBN{In British English, “i.e.” and “e.g.” are not followed by a comma. Virtually all American style guides recommend to follow both “i.e.” and “e.g.” with a comma(just like if “that is” and “for example” were used instead)}
\commentOC{That some people that are not British choose to write in British English has always puzzled me. That’s a bit like choosing to count in French from France instead of French from Switzerland when one has a choice. Anyway.}\commentBN{I'm not American either. It's matter of choosing a standard and be consistent. BTW I don't have a preference for any of them.}
if we ask all voters to judge the same $k$ alternatives, then we have complete knowledge restricted to this set of candidates. As defined in \Cref{sec:complete}, we call $P^{K_j}$ the restriction of the complete profile $P$ to only the alternatives in $K_j$.
\commentOC{I wonder if this notation will be useful.}

Let $g:\overline{\triangle}^N\rightarrow \bigcup_{N' \subseteq N}\triangle^{N'}$ be a function that given an incomplete vector of grades returns the vector composed only of the "defined" grades. 
\commentOC{… for some $x \in …$. But it would be nicer to not lose the identity of the voters here as this is unrelated to the removal of the Undefined grades, the real goal of the $g$ operation. Using all possible subsets $N'$ of $N$ instead of all $x$ would achieve this.
Also, specify that given $q \in …$, thus, $q \subseteq N × \triangle bar$, $g(q) = \restr{q}{N × \triangle}$.}\commentBN{I'm not sure I get this.}

%The operator $\overline{\rho}$ defines a restricting ordering function that given $\overline{P_i}$, an incomplete vector of $n$ grades, returns the correspondent complete vector restricted to its $x$ "defined" grades decreasingly ordered: $\overline{\rho}(\overline{P_i})=\rho(d(\overline{P_i}))$. \commentBN{Not sure this is necessary.}

Given any $S \subseteq A$, the \emph{majority-grade} for incomplete profile $\overline{f}^S_{maj}: (\bigcup_{x \in \intvl{1,n}}\triangle^{x})^S \rightarrow \triangle^S$ corresponds to $f^S_{maj}$ that only considers the "defined" grades in the computation of the median. Denote by $P'=g(\overline{P}^S_i)$, then $\overline{f}^S_{maj}(P')_i = \rho(P')_{\floor{\frac{\card{P'}}{2}} + 1}$, $\forall i \in S$. 
\commentOC{$P^S_i$ bar is undefined. And $P'$ doesn’t seem to have the right type.}

To summarize, starting with zero knowledge, we ask the voters to judge $k$ candidates. Given the partial information at our disposal, we are able to define the "known" median grade for each alternative. We can now use the \emph{selection function} $F^S_k$, defined in \Cref{sec:complete}, to select the $k$ alternatives with the highest "known" median grades.

Given the set $\tilde{K}=F^S_k(g(\overline{P}^S_i))$ of the best $k$ alternatives, every voter is then asked to judge all the candidates in $\tilde{K}$. 
This process results in a restriction $P^{\tilde{K}}$ of the complete profile $P$. It is important to mention that when we ask the voters to judge an alternative $i\in \tilde{K}$ we assume that they report their preference as they would have stated it when asked about $P$. In other words, $P^{\tilde{K}}_{i} = P_i$ for any $i \in \tilde{K}$.

Please note that $P^{\tilde{K}}$ is a complete matrix of $kn$ grades and that we fall back to the complete profile case, thus, we apply the \emph{majority-grade}, $f^{\tilde{K}}_{maj}$, function to $P^{\tilde{K}}$ to determine the median grades and then the winner function $F^{\tilde{K}}_{maj}$ to select the winner. 
%For simplicity we denote by $\overline{W}_{\overline{P^k}} \subseteq A$ the results of this process.

\begin{remark}
	Because we are interested into investigating \acs{MJ}, we are going to use an alphabet with the same size of the one proposed by \citet{Balinski2011} which is composed of the following adjectives: Excellent, Very good, Good, Average, Mediocre, Inadequate, To be Rejected. For brevity we are gonna rename those adjectives respectively from $\delta_7$, corresponding to Excellent, to$\delta_1$, corresponding to To be Rejected. Therefore, $\triangle=\{\delta_1,\delta_2, \delta_3,\delta_4,\delta_5,\delta_6,\delta_7\}$ 
\end{remark}

Once having defined the notation, the first question that comes to mind is about the risks of incomplete knowledge. Given a profile which we only partially know, would we always select the same set of alternatives as winners in case of complete and incomplete knowledge?
\commentOC{The phrasing of this question could be improved: as stated, the answer is, I suppose, obviously negative. With low knowledge, there is not much hope that the right alternatives would be selected.}

\begin{proposition}
	\label{prop:notsamewinner}
	Given $A$ a set of $m\geq 3$ alternatives and $N$ a set of $n\geq3$ voters, there exist a complete profile $P$ and an incomplete profile $\overline{P} \subset P$, such that $F_{maj}(P) \nsubseteq F^{\tilde{K}}_{maj}(P^{\tilde{K}})$ \textemdash where $\tilde{K}=F^S_k(g(\overline{P}^S_i))$.
	\commentOC{As proof I’d suggest: assume we never ask about some alternative $i$ which is judged excellent by everybody; and all the other ones are judged the worst.}
\end{proposition}
\begin{proof}
	Pick an alternative $i\in A$ and a voter $j \in N$, let us build a profile $P$ in the following way: the voter $j$ judges $\delta_1$ the alternative $i$ and she judges $\delta_2$ all the other alternatives $x \in A \setminus \{i\}$; every other voter $y\in N \setminus \{j\}$ judges $\delta_7$ the alternative $i$ and $\delta_6$ all the other alternatives $x \in A \setminus \{i\}$. The resulting profile $P$ will have the form:
	\begin{center}
		$
		\begin{array}{ccccccc}
			& j_1 & j_2 & \dots & j & \dots & j_n \\
			i_1 &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			i_2 &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			. &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			i &	\delta_7 & \delta_7 & \dots & \delta_1 & \dots & \delta_7 \\
			. &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
			i_m &	\delta_6 & \delta_6 & \dots & \delta_2 & \dots & \delta_6 \\
		\end{array} \quad.
		$
	\end{center}
	For $n\geq 3$ the median grade $f_{maj}(P_i)=\delta_7$ and $f_{maj}(P_x)=\delta_6, \forall x \in A \setminus \{i\}$. Thus, the winner $F_{maj}(P)=\{i\}$.
	
	Consider now any $k \in \intvl{1,m-1}$, and remove from $P$ as many judgments as necessary such that the following conditions are verified: each column only contains $k$ grades \textemdash meaning that each voter judges $k$ candidates \textemdash and the row corresponding to the alternative $i$ is only formed by two grades, one $\delta_7$ and one $\delta_1$ \textemdash we have only the best and worst opinion on $i$. We fill all the unknown judgments with \textit{Undefined} grades to obtain $\overline{P}$. Note that we only have two judgments for the alternative $i$ so $\overline{f}_{maj}(\overline{P}_i)=\delta_1$ and, since $m\geq3$ and $1 \leq k \leq m-1$, $\overline{f}_{maj}(\overline{P}_x)$ is either $\delta_6$ or $\delta_2$ $\forall x \in A \setminus \{i\}$. Therefore $\overline{f}_{maj}(\overline{P}_x) > \overline{f}_{maj}(\overline{P}_i)$ $\forall x \in A \setminus \{i\}$, this means that $i$ will not be selected for the second turn, when we ask the voters their complete preferences about the $k$ "best" alternatives. Thus $i \notin \tilde{K}$ and, consequently, $F_{maj}(P) \nsubseteq F^{\tilde{K}}_{maj}(P^{\tilde{K}})$.
\end{proof}

\commentBN{Stopped here.}

\section{Reasoning on incompleteness}
Let us denote by $W^*=F_{maj}(P)$ the set of winners associated to the complete profile $P$, and recall that $\overline{W}_{\overline{P^k}}$ indicates the set of winners associated to the incomplete profile $\overline{P^k}$.

As we observed in \Cref{prop:notsamewinner}, given an incomplete profile $\overline{P^k} \subset P$ it is possible to elect a candidate as a winner that would not be selected when considering (one of) its completion $P \in C(\overline{P^k})$. In this section we want to investigate how likely it is to happen.

Assume that the complete profile $P$ exists but it is unknown to us, the knowledge we have is represented by $\overline{P^k}$ and the voters are truthful. 
\commentOC{I would not repeat this, it is clear already, and it is strange to repeat it here and not elsewhere. And, you’d need to define truthful.}
This means that starting from $\overline{P^k}$, by asking each voter to judge every alternative we converge to $P$.

Consider an alternative $w\in A$ and observe that for $w$ to be in $W^*$ we need $f_{maj}(P_w)\geq f_{maj}(P_i), \ \forall i \in A$. 
Consider now the incomplete profile $\overline{P^k}$ and the set of the $k$ alternatives with the highest "known" median grades $\tilde{K}$. 
\commentOC{Do you mean, the set $\tilde{K}$ of the $k$ alternatives…?}
Let $v$ be the $k$-th highest median, i.e. $v=\min_{i\in \tilde{K}} \overline{f}_{maj}(\overline{P_i})$ the lowest grade of an alternative in $\tilde{K}$. If $\overline{f}_{maj}(\overline{P}_w) \geq v$ then $w \in \tilde{K}$. 
\commentOC{A notation for the $x$th median grade or $x$th best alternative would be useful.}\commentBN{ok}

Because the voters express their judgments on all the alternatives in $\tilde{K}$ 
\commentOC{The reason for this claim is unclear to me. Is this a deduction, or an hypothesis?}\commentBN{Need more clarity, this should be clear.}
and $P^{\tilde{K}}_{i} = P_i$ for any $i \in \tilde{K}$, then if $w \in W^*$ and $w \in \tilde{K}$ then $w \in \overline{W}_{\overline{P^k}}$.

In order to compute the probability of a winning alternative $w$ to not be elected in case of incompleteness, we need to focus on the probability for $w$ not to reach the second round: probability of $w \notin \tilde{K}$.
\commentBN{If I'm the winner here are three cases I'm not elected in incompleteness:
\begin{itemize}
	\item I'm demoted $\Rightarrow \overline{h}<h$
	\begin{itemize}
		\item others are promoted $\Rightarrow v>\overline{h}$
		\item or not $\Rightarrow v>\overline{h}$
	\end{itemize}
	\item $\overline{h}=h$
	\begin{itemize}
		\item others are promoted $\Rightarrow v>\overline{h}$
	\end{itemize}
	\item I'm promoted $\Rightarrow \overline{h}>h$
	\begin{itemize}
		\item others are promoted $\Rightarrow v>\overline{h}$
	\end{itemize}
\end{itemize}}

Consider the complete profile $P$ and the highest median grade $h=\max_{i\in A}\rho(P_i)_{\floor{\frac{n}{2}} + 1}$. Since $w \in W^*$ then $f_{maj}(P_{w})\geq h$ and the vector of grades $P_w$ must be composed of at least $\floor{\frac{n}{2}}+1$ grades $\alpha \geq h$ and at most $\lceil \frac{n}{2}\rceil-1$ of grades $\beta < h$. Let us evaluate the worst case scenario.
Without loss of generality consider $n$ an odd value, then the vector $P_{w}$ in the worst case contains exactly $\frac{n+1}{2}$ grades greater than or equal to $h$ and $\frac{n-1}{2}$ grades lower than $h$.
\[P_w : \qquad [ \alpha_1, \dots , \alpha_{\frac{n+1}{2}}, \beta_1, \dots , \beta_{\frac{n-1}{2}} ] \]
Consider now the incomplete profile $\overline{P^k} \subset P$ and the highest "known" median $v$ described above. For $w \notin \tilde{K}$ then $\overline{f}_{maj}(\overline{P^k}_w) < v$ and the partial vector $\overline{P^k}_w$ of $x\in \intvl{1,n-1}$ defined grades must be composed of at least $\frac{x+1}{2}$ grades $\beta'<v$ and at most $\frac{x-1}{2}$ grades $\alpha' \geq v$. 

If $h=v$, we have $\binom{(n+1)/2}{(x-1)/2}$ ways of picking $\frac{x-1}{2}$ grades greater than or equal to $v$ out of the $\frac{n+1}{2}$ of the original vector; and $\binom{(n-1)/2}{(x+1)/2}$ ways of picking $\frac{x+1}{2}$ grades lower than $v$.
\begin{align}
	P_{w}: \qquad [ \underbrace{\alpha_1, \dots , \alpha_{\frac{n+1}{2}}}_{\begin{pmatrix}\frac{n+1}{2} \\ \frac{x-1}{2}\end{pmatrix}}, \underbrace{\beta_1, \dots , \beta_{\frac{n-1}{2}}}_{\begin{pmatrix}\frac{n-1}{2} \\ {\frac{x+1}{2}}\end{pmatrix}} ] \\
	\overline{P^k}_w:\qquad [ \overbrace{\alpha'_1, \dots , \alpha'_{\frac{x-1}{2}}}, \overbrace{\beta'_1, \dots , \beta'_{\frac{x+1}{2}}}]
\end{align} 
\newcommand{\largemath}[1]{{\mathlarger{\mathlarger{\mathlarger{\mathlarger{\mathlarger#1}}}}}}
%note to myself: find a better way please

We define the probability of $w \notin \tilde{K}$ as the number of incomplete vectors $\overline{P^k}_w$ for which $\overline{f}_{maj}(\overline{P^k}_w) < v$, over the total number of possible incomplete vectors:
\commentBN{prob of w to be demoted in worst case}
\[ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n+1}{2} \\ {\frac{x-1}{2}-i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n-1}{2} \\ {\frac{x+1}{2}+i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} } \]

\commentBN{prob of w to be demoted for $\beta$ going from $j=0$ to $(n-1)/2$}

\[ P(\overline{h}<h)= \largemath{\sum}_{j=0}^{(n-1)/2}{ \ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n+1}{2}+j \\ {\frac{x-1}{2}-i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n-1}{2}-j \\ {\frac{x+1}{2}+i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} }} \]

\commentBN{prob of w to be promoted for $\alpha$ going from $j=0$ to $(n-1)/2$ where: the vector of grades $P_w$ must be composed of at least $\floor{\frac{n}{2}}+1$ grades $\alpha > h$ and at most $\lceil \frac{n}{2}\rceil-1$ of grades $\beta \leq h$.}

\[ P(\overline{h}>h)= \largemath{\sum}_{j=0}^{(n-1)/2}{ \ \largemath{\sum}_{x=1}^{n-1}{ \frac{ \largemath{\sum}_{i=0}^{x/2}{ \begin{pmatrix}\frac{n-1}{2}-j \\ {\frac{x+1}{2}+i}\end{pmatrix} \cdot \begin{pmatrix}\frac{n+1}{2}+j \\ {\frac{x-1}{2}-i}\end{pmatrix} }}{\begin{pmatrix}n \\ x\end{pmatrix}} }} \]

\commentBN{$P(\overline{h}=h)= 1-P(\overline{h}>h)\cdot P(\overline{h}<h)$ : probability of being properly labeled}

The size $x$ of an incomplete vector $\overline{P_i}$ for $i \in A$, depends on the number of questions $k$ asked to the voters, in fact, if we ask $n$ voters to judge $k$ random alternatives, ideally, each alternative $i$ will be judged $\frac{k\cdot n}{m}$ times. Consider the value $k$ as a function of the number of alternatives: $k=c \cdot m$ where $c \in \R$. If $m=10$ and $k=5$ then $k=1/2 m$, i.e. we ask the voters to judge half of the candidates. Thus, the value $x$ depends only on the number of voters $n$ $x=\frac{k\cdot n}{m}= c \cdot n$, $c\in \R$. Without loss of generality we consider both $x$ and $n$ odd values.

Consider the worst case scenario: the real vector $P_{w^*}$ has a proportion of $51\%-49\%$ of $\alpha-\beta$ grades. \Cref{fig:differentX51-49} shows the probability of electing a non-real winner in this scenario for different size $x$ of the incomplete vector $\overline{P_{w^*}}$. \Cref{tab:differentX51-49} shows in details those values. Note that when $x=1001$ the probability is about $25\%$, but we should keep in mind that $x= c \cdot n$, thus a vector of size $1000$ means that the alternative $w^*$ was judged by only $1/10$ of the voters. With this in mind, we see that with $x=\frac{n}{2}$ we obtain a very low probability of only $2.12\%$, but we need $4/5$ of the voters to judge each alternative to get zero probability of "miss-qualification".

The situation change drastically for different proportions of $\alpha-\beta$ grades as \Cref{fig:differentX} shows. In particular, we only need about $200$ judgments (thus $1/50$n) to reach an almost zero probability of electing a non real winner when the real vector $P_{w^*}$ has a proportion of $60\% \alpha -40\% \beta$ grades. Recalling the formula:
\begin{align}
	x&=\frac{k \cdot n}{m} \\
	200&=\frac{k}{m}\cdot 10000 \\
	\frac{1}{50}&=\frac{k}{m} \\
	k&=\frac{m}{50}
\end{align}
we note that asking one question per voter is more than enough to avoid the election of a non-real winner.

In the 2016 elections organised by LaPrimaire.org $n=10675$ voters participated in the first round, and each of them judged $k=5$ random alternatives out of the $m=12$ total ones. Each alternative received an average of $4449$ judgments. Using this data, we simulated th probability of electing a non-real winner for different proportions of $\alpha-\beta$ grades. \Cref{fig:original} and \Cref{tab:original} show the results.

By crossing these results we note that we could have asked the voters far less than $5$ questions, reducing the communication and the cognitive cost of the elicitation process.

%xticklabel style = {font=\footnotesize},
%x label style={at={(axis description cs:0.5,-0.05)},anchor=north}
\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ylabel=Prob. \%,
			xlabel= x,
			ymin=0,
			ymax=50,
			xmin=1,
			xmax=10001,
			xtick={1,1001,2001,3001,4001,5001,6001,7001,8001,9001,10001},
			xticklabels={$10^{-3}$,1,2,3,4,5,6,7,8,9,10},
			xticklabel style = {yshift=-0.5ex},
			scaled x ticks= real:1000,
			x label style={at={(axis description cs:0.5,-0.03)},anchor=north}
			]
			\addplot[thick, blue] table [x=x, y=ProbOfMiss, col sep=comma]{data/51-49-100.csv};			
		\end{axis}
	\end{tikzpicture}
	\caption{Probability of electing a non-real winner, for different values of $x$, with $n=10000$, and $51\%-49\%$ proportion of $\alpha - \beta$ grades.}
	\label{fig:differentX51-49}
\end{figure}

\sisetup{table-number-alignment = center, table-figures-integer=2, table-figures-decimal=1, table-auto-round}
\begin{table}
	\centering
	\begin{tabular}{S[table-figures-integer=5, table-figures-decimal=0]S[table-figures-integer=2, table-figures-decimal=2]}
			\toprule
			{x} & {Prob. of Miss} \\
			\midrule
			1	&	48.9853044087	\\
			1001	&	24.9190117413	\\
			2001	&	15.5009678852	\\
			3001	&	9.1920240364	\\
			4001	&	4.8710050444	\\
			5001	&	2.1180123415	\\
			6001	&	0.645530701	\\
			7001	&	0.096388706	\\
			8001	&	0.0024354987	\\
			9001	&	0.000000051	\\
			10001	&	0.00	\\
			\bottomrule
		\end{tabular}
	\caption{Detailed numbers of \Cref{fig:differentX51-49}.}
	\label{tab:differentX51-49}
\end{table}

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ylabel=Prob. \%,
			xlabel= x,
			ymin=0,
			ymax=50,
			xmin=1,
			xmax=201,
			enlarge x limits=-1, %hack to plot on the full x-axis scale
			width=13cm, %set bigger width
			height=6cm,
			legend style={font=\scriptsize}
			]
			\addlegendimage{mark=*,teal,mark size=1.5}
			\addlegendimage{mark=triangle*,orange,mark size=1.5}
			\addlegendimage{mark=square*,blue,mark size=1.5}
			\addlegendimage{mark=diamond*,red,mark size=1.5}
			
			\addplot[thick, mark=*, mark size = {2}, mark indices = {15}, teal] table [x=x, y=ProbOfMiss, col sep=comma]{data/60-40-2.csv};
			\addlegendentry{$60\%-40\%$}
			\addplot[thick, mark=triangle*, mark size = {2}, mark indices = {6}, orange] table [x=x, y=ProbOfMiss, col sep=comma]{data/70-30-2.csv};
			\addlegendentry{$70\%-30\%$}	
			\addplot[thick, mark=square*, mark size = {2}, mark indices = {4}, blue] table [x=x, y=ProbOfMiss, col sep=comma]{data/80-20-2.csv};	
			\addlegendentry{$80\%-20\%$}
			\addplot[thick, mark=diamond*, mark size = {2}, mark indices = {2}, red] table [x=x, y=ProbOfMiss, col sep=comma]{data/90-10-2.csv};			
			\addlegendentry{$90\%-10\%$}
		\end{axis}
	\end{tikzpicture}
	\caption{Probability of electing a non-real winner, for different values of $x$ and different proportion of $\alpha - \beta$ grades, with $n=10000$.}
	\label{fig:differentX}
\end{figure}


\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			ylabel=Prob. of Miss \%,
			xlabel=Percentage of $\alpha$ Grades \%,
			ymin=0,
			ymax=5,
			xmin=5445,
			xmax=9608,
			scaled ticks = false,
			xtick={5445,6405,7473,8540,9608},
			xticklabels={51,60,70,80,90}
			]
			\addplot[thick, red] table [x=BetterThanMed, y=ProbOfMiss, col sep=comma]{data/original.csv};			
		\end{axis}
	\end{tikzpicture}
	\caption{Probability of electing a non-real winner, for $n=10675$, $x=4449$ and different proportion of $\alpha - \beta$ grades.}
	\label{fig:original}
\end{figure}

\begin{table}
	\centering
	\begin{tabular}{cc}
		\toprule
		{$\alpha-\beta$} & {Prob. of Miss} \\
		\midrule
		$51\%-49\%$	&	3.92	\\
		$60\%-40\%$	&	2.79$10^{-69}$	\\
		$70\%-30\%$	&	5.80$10^{-318}$	\\
		$80\%-20\%$	&	0.00	\\
		$90\%-10\%$	&	0.00	\\
		\bottomrule
	\end{tabular}
	\caption{Detailed numbers of \Cref{fig:original}.}
	\label{tab:original}
\end{table}

\subsection{Unfixed k}

A natural question that comes to mind when considering the process of asking the voters to judge random alternatives is: how feasible is it? Especially when applying it to political elections, it is safe to say that voters have strong opinions. There are always some candidates that we would never want to see in office, while we would really like to support our favorite candidate. By applying the random selection of questions there is a chance we do not get to express our opinions on those particular candidates. In the worst case, we may be asked to judge only candidates of whom we do not have a strong opinion, or worse, that we do not even know. Is our judgment relevant in this case? How willing are we to take the risk to go and vote without the certainty of being able to express the judgments we consider important?

Because of all these reasons, we may want to consider the possibility for the voters to choose the candidates to judge. One extreme situation that may occur is that each voter judges only its best and worst choice. 

\begin{proposition}
	Given two integers $k=5$ and $s=5$, $m$ alternatives and $n$ voters who only judge their best and worst candidates, there exist a complete profile $P'$ and an incomplete profile $\overline{P'}$ such that $P'\in C(\overline{P'})$ and $F(P')\neq F(\overline{P'})$.
\end{proposition}	

\begin{proof} Consider the following complete profile $P$:

	\begin{center}
		\begin{tabular}{cccccccc}
			& j$_1$ & j$_2$ & j$_3$ \\
			a	&	Average	&	Average	&	Excellent	\\
			b	&	To be rejected	&	Good	&	Good	\\
			c	&	Mediocre	&	Excellent	&	Mediocre	\\
			d	&	Average	&	Average	&	To be rejected	\\
			e	&	Mediocre	&	To be rejected	&	Mediocre	\\
			f	&	Excellent	&	Inadequate	&	Inadequate \\
		\end{tabular}
	\end{center}
	
	
	for the sake of the example the rows are not ordered vectors because the identity of the voters is considered.
	
	The vector of medians $f_{maj}(P)$ is:
	\begin{center}
		$
		\begin{array}{cc}
			a &	Average \\
			b &	Good \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Inadequate \\
		\end{array} \quad.
		$
	\end{center}
	The real winner is $F^P=b$. 
	
	Assume that each voter only express its best and worst judgments and construct the complete profile $P'$ from $P$ in the following way: for each alternative $i$ that is not the real winner $w^*$ add as many voters as needed such that its known median grade ($f_{maj}(\overline{P'_i})$) is better than the known median grade of the real winner ($f_{maj}(\overline{P'_{w^*}})$); then add an additional alternative that is rejected by all these new voters. Since the voters only express the best and the worst grades, we are not interested in how they judge the rest of the alternatives, to construct a complete profile we can assume that they judge them according to the current known median. The resulting complete profile $P'$ is the following, but our information $\overline{P'}$ is only restricted to the green values: 

		\scalebox{0.75}{
			\begin{tabular}{cccccccc}
				& j$_1$ & j$_2$ & j$_3$ & j$_4$ & j$_5$ & j$_6$ & j$_7$ \\
				a	&	Average	&	Average	&	{\color{teal}Excellent}	&	Average	&	Average	&	Average	&	Average	\\
				b	&	{\color{teal}To be rejected}	&	Good	&	Good	&	Good	&	Good	&	Good	&	Good	\\
				c	&	Mediocre	&	{\color{teal}Excellent}	&	Mediocre	&	Mediocre	&	Mediocre	&	Mediocre	&	Mediocre	\\
				d	&	Average	&	Average	&	{\color{teal}To be rejected}	&	{\color{teal}Excellent}	&	{\color{teal}Excellent}	&	Average	&	Average	\\
				e	&	Mediocre	&	{\color{teal}To be rejected}	&	Mediocre	&	Mediocre	&	Mediocre	&	{\color{teal}Excellent}	&	{\color{teal}Excellent}	\\
				f	&	{\color{teal}Excellent}	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	&	Inadequate	\\
				g	&	{\color{teal}To be rejected}	&	{\color{teal}To be rejected} & {\color{teal}To be rejected}& {\color{teal}To be rejected} & {\color{teal}To be rejected} & {\color{teal}To be rejected} & {\color{teal}To be rejected}	\\
			\end{tabular}
		}
		
	The vector of medians $f_{maj}(\overline{P'})$ is:
	\begin{center}
		$
		\begin{array}{cc}
			a &	\text{Excellent} \\
			b &	\text{To be rejected} \\
			c &	\text{Excellent} \\
			d &	\text{Excellent}	\\
			e &	\text{Excellent} \\
			f & \text{Excellent} \\
			g & \text{To be rejected} \\
		\end{array} \quad.
		$
	\end{center}
	The real winner $b$ does not appear in the set of candidates for the second round $S=\{a,c,d,e,f\}$, so it will not be elected from the incomplete profile $\overline{P'}$.
\end{proof}
	



\newpage
\paragraph{My draft - do not read}
\begin{itemize}
	\item Does expressing judgment on randomly selected candidates influence the result? (If we change the questions does the result change?)
	\item Does the number of questions influence the result? (If we change the number of questions does the result change?)
	\item If yes, do these effects are mitigated by a second round?
	\item Which is the right number of questions? (Best trade-off between communication cost and optimal result.)
	\item Can we select the next question with minimax regret instead of randomly selecting a candidate?
	\item Can we say anything about the "fairness" of proposing the candidates to judge? Suppose I have strong opinions about only two candidates: one I extremely like and one I extremely dislike. There is a chance I will not be asked about those two candidates, in this case I cannot say much about the other candidates and I am also frustrated because I did not get to express my opinions.
	\item Consider $n$ voters and $m$ candidates and assume that a voter $i \in N$ judges only a fraction of the $m$ candidates. What is the resulting voting rule? What are its properties? Can a voter manipulate the result by judging only some candidates? 
\end{itemize}

\newpage
\bibliography{biblio}
\newpage
\appendix
\section{Old material that can be transformed into examples}
\begin{proof} Consider $n=3, m=6, k=5$ and the following complete profile $P$:
	\begin{center}
		$
		\begin{array}{cccc}
			& j_1 & j_2 & j_3 \\
			a &	Excellent	& Excellent & Inadequate\\
			b &	Mediocre	& Mediocre	& Mediocre\\
			c &	Mediocre	& Mediocre & Inadequate\\
			d &	Average	& Average	& Average\\
			e &	Average	& Mediocre	& Inadequate \\
			f &	Average	& Mediocre & Mediocre	  \\
		\end{array} \quad.
		$
	\end{center}
	The vector of medians $f_{maj}(P)$ is:
	\begin{center}
		$
		\begin{array}{cc}
			a &	Excellent \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Mediocre \\
		\end{array} \quad.
		$
	\end{center}
	The real winner is $F^P=a$. 
	
	Consider now the following incomplete profiles $\overline{P}$ and $\overline{P}'$ obtained after having asked each voter to judge $k=5$ random chosen alternatives: \commentOC{This mixes again the process and the maths. The proposition does not talk about randomness and it is confusing to refer to this here. The proposition holds whatever the way $P$ bar is chosen (including, deterministically).}\commentBN{I'm not sure I got this. With randomness I mean the one in the definition of $\overline{P}$.}
	\begin{center}
		$\overline{P}: \qquad
		\begin{array}{cccc}
			& j_1 & j_2 & j_3 \\
			a &	Excellent	& {\color{red}Undefined} & Inadequate\\
			b &	Mediocre	& Mediocre	& Mediocre\\
			c &	Mediocre	& Mediocre & Inadequate\\
			d &	Average	& Average	& {\color{red}Undefined} \\
			e &	Average	& Mediocre	& Inadequate \\
			f &	{\color{red}Undefined}	& Mediocre & Mediocre	  \\
		\end{array} \quad,
		$
	\end{center}
	\begin{center}
		$\overline{P}': \qquad
		\begin{array}{cccc}
			& j_1 & j_2 & j_3 \\
			a &	Excellent	& Excellent & Inadequate\\
			b &	Mediocre	& {\color{red}Undefined}	& Mediocre\\
			c &	Mediocre	& Mediocre & {\color{red}Undefined}\\
			d &	Average	& Average	& Average \\
			e &	{\color{red}Undefined}	& Mediocre	& Inadequate \\
			f &	Average	& Mediocre & Mediocre	  \\
		\end{array} \quad.
		$
	\end{center}
	The vector of medians are:
	\begin{center}
		$f_{maj}(\overline{P})= \quad
		\begin{array}{cc}
			a &	Inadequate \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Mediocre \\
		\end{array} \quad,\quad%
		f_{maj}(\overline{P}')= \quad
		\begin{array}{cc}
			a &	Excellent \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Inadequate \\
			f & Mediocre \\
		\end{array} \quad.
		$
	\end{center}
	
	Consider the sets of $s=5$ alternatives with the highest median grades for the two profiles, $S'=\{b,c,d,e,f\}$ for $\overline{P}$, and $S^{\prime\prime}=\{a,b,c,d,f\}$ for $\overline{P}'$, and the two restrictions $P_{S'}$ and $P_{S^{\prime\prime}}$. In particular, $P_{S'}$ corresponds to the complete profile when eliminating the alternative $a$, and $P_{S^{\prime\prime}}$ to the complete profile without the alternative $e$.
	The vector of medians are:
	\begin{center}
		$f_{maj}(P_S')= \quad
		\begin{array}{cc}
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			e &	Mediocre \\
			f & Mediocre \\
		\end{array} \quad,\quad%
		f_{maj}(P_S^{\prime\prime})= \quad
		\begin{array}{cc}
			a & Excellent \\
			b &	Mediocre \\
			c &	Mediocre \\
			d &	Average	\\
			f & Mediocre \\
		\end{array} \quad.
		$
	\end{center}
	The winner associated to the incomplete profile $\overline{P}$ is then $F^{P_{S'}} = d$ and the one associated to $\overline{P}'$ is $F^{P_{S^{\prime\prime}}} = a$, thus $F^{\overline{P}} \neq F^{\overline{P}'}$.
\end{proof}
\commentOC{Perhaps some part of this could be transformed to an example.}

\begin{corollary}
	Given $m$ alternatives, $n$ voters and an integer $k \in \intvl{1,m}$, there exist a profile $P$ and an incomplete profile of $P$, $\overline{P}$, such that $F^{\overline{P}}$ is not the real winner.
\end{corollary}
\commentOC{“real winner” is inappropriate here. Is there an unreal winner? I realize that you mean “winner considering the complete profile” VS “winner considering some part of it”, but I don’t think that the term “real” is appropriate. I’d simply say “winners” for the winners of the complete election, and perhaps “approximate winners” for the winners given a partial profile, or something similar.}

\end{document}

